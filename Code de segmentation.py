# -*- coding: utf-8 -*-
"""Mrcnn11_Copie.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ixCvsAAk597qdzsoYC5pZjrgEDTYWSwm
"""

!git clone https://github.com/z-mahmud22/Mask-RCNN_TF2.14.0.git

cd Mask-RCNN_TF2.14.0

import sys
print(sys.version)

# Install the Mask R-CNN-specific dependencies
!pip install -r requirements.txt

!python3 setup.py install

# Bibliothèques scientifiques de base
import numpy as np
import pandas as pd
import scipy.stats as stats

# Visualisation
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

# Machine Learning et Deep Learning
import tensorflow as tf
import keras
from keras import backend as K
import mrcnn
from mrcnn.config import Config
from mrcnn.model import MaskRCNN
from mrcnn.utils import Dataset

# Computer Vision
import cv2
import imgaug
import albumentations as A
from skimage import io, transform

# Traitement de données
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    mean_squared_error
)

# Autres utilitaires
import os
import json
import sys
import time
import random
from tqdm import tqdm

# Image et annotations
import pycocotools.coco as coco
import h5py
from PIL import Image

from google.colab import drive
drive.mount('/content/drive')

import os
from pycocotools.coco import COCO

# Specify the path to your dataset (change the path accordingly)
data_dir = '/content/drive/MyDrive/KOALA.v1i.coco/'

import os
import logging
from typing import List, Tuple, Optional

import numpy as np
from pycocotools.coco import COCO
from mrcnn.utils import Dataset

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class KOALADataset(Dataset):
    def load_KOALA(self, dataset_dir: str, subset: str) -> None:
        """
        Load a subset of the KOALA dataset.

        Args:
            dataset_dir: Root directory of the dataset.
            subset: The subset to load: 'train', 'valid', or 'test'.

        Raises:
            FileNotFoundError: If dataset directory or annotations file is missing.
            ValueError: If subset is not valid.
        """
        # Validate subset
        valid_subsets = ['train', 'valid', 'test']
        if subset not in valid_subsets:
            raise ValueError(f"Invalid subset. Must be one of {valid_subsets}")

        # Add class
        self.add_class("KOALA", 1, "KOALA")

        # Validate dataset directory
        if not os.path.exists(dataset_dir):
            raise FileNotFoundError(f"Dataset directory not found: {dataset_dir}")

        # Define the path to the annotation file for the current subset
        annotations_path = os.path.join(dataset_dir, subset, '_annotations.coco.json')

        if not os.path.exists(annotations_path):
            raise FileNotFoundError(f"Annotations file not found: {annotations_path}")

        try:
            # Load the COCO annotations for the current subset
            coco = COCO(annotations_path)

            # Add images to the dataset
            image_ids = coco.getImgIds()
            logger.info(f"Loading {len(image_ids)} images from {subset} subset")

            for image_id in image_ids:
                image_info = coco.loadImgs(image_id)[0]
                image_path = os.path.join(dataset_dir, subset, image_info['file_name'])

                if not os.path.exists(image_path):
                    logger.warning(f"Image not found: {image_path}")
                    continue

                self.add_image(
                    "KOALA",
                    image_id=image_id,
                    path=image_path,
                    width=image_info['width'],
                    height=image_info['height']
                )

        except Exception as e:
            logger.error(f"Error loading KOALA dataset: {e}")
            raise

    def load_mask(self, image_id: int) -> Tuple[np.ndarray, np.ndarray]:
        """
        Load instance masks for an image.

        Args:
            image_id: Unique identifier for the image.

        Returns:
            A tuple of masks (numpy array) and corresponding class IDs.
        """
        try:
            info = self.image_info[image_id]
            annotations_path = os.path.join(os.path.dirname(info['path']), '_annotations.coco.json')

            coco = COCO(annotations_path)
            ann_ids = coco.getAnnIds(imgIds=info['id'])
            annotations = coco.loadAnns(ann_ids)

            masks = []
            class_ids = []
            for ann in annotations:
                mask = coco.annToMask(ann)
                masks.append(mask)
                class_ids.append(self.map_category_id(ann['category_id']))

            # Handle empty masks scenario
            if not masks:
                masks = np.zeros((info['height'], info['width'], 0), dtype=np.uint8)
                class_ids = np.array([], dtype=np.int32)
            else:
                masks = np.stack(masks, axis=-1)
                class_ids = np.array(class_ids)

            return masks, class_ids

        except Exception as e:
            logger.error(f"Error loading mask for image {image_id}: {e}")
            raise

    def map_category_id(self, original_id: int) -> int:
        """
        Map original category IDs to dataset-specific class IDs.

        Args:
            original_id: Category ID from original dataset.

        Returns:
            Mapped class ID for the dataset.
        """
        # Example mapping - adjust based on your specific dataset
        return 1  # Default to KOALA class

    def image_reference(self, image_id: int) -> str:
        """
        Get the file path for a given image ID.

        Args:
            image_id: Unique identifier for the image.

        Returns:
            Absolute file path of the image.
        """
        return self.image_info[image_id]['path']

# Initialize and load the training dataset
dataset_train = KOALADataset()
dataset_train.load_KOALA(data_dir, 'train')
dataset_train.prepare()

# Initialize and load the validation dataset
dataset_val = KOALADataset()
dataset_val.load_KOALA(data_dir, 'valid')
dataset_val.prepare()

# Initialize and load the testing dataset
dataset_test = KOALADataset()
dataset_test.load_KOALA(data_dir, 'test')
dataset_test.prepare()

!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5

# Import necessary libraries
from mrcnn.model import MaskRCNN
from mrcnn.config import Config

# Define your custom configuration class
class CustomConfig(Config):
    """
    Configuration for training on a custom dataset.
    Adjust the parameters to fit your dataset and hardware.
    """
    NAME = "koala"  # Name of the dataset or task
    IMAGES_PER_GPU = 2  # Adjust this based on the memory of your GPU
    NUM_CLASSES = 1 + 1  # Background (1) + koala (1)
    STEPS_PER_EPOCH = 100  # Number of training steps per epoch
    VALIDATION_STEPS = 50  # Number of validation steps at the end of each epoch
    LEARNING_RATE = 0.001  # Initial learning rate
    IMAGE_MIN_DIM = 512  # Minimum image dimension for resizing
    IMAGE_MAX_DIM = 512  # Maximum image dimension for resizing
    GPU_COUNT = 1  # Number of GPUs to use

    # Add other optional parameters as needed, for example:
    # BACKBONE = "resnet50"  # Backbone architecture (default: resnet101)
    # RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)  # Anchor box scales

# Instantiate your custom configuration
config = CustomConfig()

# Display configuration to verify settings
print("Custom configuration:")
for attribute, value in vars(config).items():
    print(f"{attribute}: {value}")

# Step 1: Create the model in training mode
model = MaskRCNN(mode="training", config=config, model_dir='/content')

# Step 2: Load pre-trained weights (COCO weights) but exclude the conflicting layers
model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=["mrcnn_bbox_fc", "mrcnn_class_logits", "mrcnn_mask"])

# Step 3: Train the model (fine-tuning only the heads)
model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=10, layers='heads')

# Sauvegarde des poids
output_weights_path = os.path.join(model.model_dir, "mask_rcnn_koala_bbox.h5")
model.keras_model.save_weights(output_weights_path)

print(f"Poids sauvegardés dans : {output_weights_path}")

import os
import matplotlib.pyplot as plt

# Sauvegarder l'historique de l'entraînement, y compris bbox loss
history_path = os.path.join('/content', 'training_logs.txt')
history = model.keras_model.history.history  # Historique d'entraînement

# Écrire les logs dans un fichier texte
with open(history_path, 'w') as log_file:
    for key, values in history.items():
        log_file.write(f"{key}: {values}\n")

print(f"Historique d'entraînement sauvegardé dans : {history_path}")

# Générer un graphique des pertes (losses)
epochs = range(1, len(history['loss']) + 1)

plt.figure(figsize=(10, 6))

# Tracer la loss totale
plt.plot(epochs, history['loss'], 'bo-', label='Training Loss')
plt.plot(epochs, history['val_loss'], 'r*-', label='Validation Loss')

# Tracer la bbox loss
if 'mrcnn_bbox_loss' in history:
    plt.plot(epochs, history['mrcnn_bbox_loss'], 'g^-', label='BBox Training Loss')
if 'val_mrcnn_bbox_loss' in history:
    plt.plot(epochs, history['val_mrcnn_bbox_loss'], 'ys-', label='BBox Validation Loss')

# Configurer le graphique
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

# Sauvegarder le graphique
plot_path = os.path.join('/content', 'loss_plot.png')
plt.savefig(plot_path)
plt.show()

print(f"Graphique des pertes sauvegardé dans : {plot_path}")

# Step 4: Generate Confusion Matrix after training
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Step 4.1: Create a model for inference
class InferenceConfig(Config):
    NAME = "KOALA"
    NUM_CLASSES = 1 + 1  # Background + koala
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1

inference_config = InferenceConfig()
inference_model = MaskRCNN(mode="inference", config=inference_config, model_dir='/content')

# Load the trained weights into the inference model
inference_model.load_weights(model.find_last(), by_name=True)

# Step 4.2: Collect true and predicted labels
true_labels = []
pred_labels = []

for image_id in dataset_test.image_ids:
    # Load true labels (class IDs) from the dataset
    true_masks, true_classes = dataset_test.load_mask(image_id)

    # Predict the image using the inference model
    image = dataset_test.load_image(image_id)
    pred = inference_model.detect([image], verbose=0)[0]

    # Align true and predicted classes
    if len(true_classes) == len(pred['class_ids']):
        true_labels.extend(true_classes)
        pred_labels.extend(pred['class_ids'])
    else:
        # Handle mismatched cases
        true_labels.extend(true_classes)
        pred_labels.extend(pred['class_ids'])

        # Fill with '0' (background class) for unmatched entries
        if len(true_classes) > len(pred['class_ids']):
            pred_labels.extend([0] * (len(true_classes) - len(pred['class_ids'])))
        elif len(pred['class_ids']) > len(true_classes):
            true_labels.extend([0] * (len(pred['class_ids']) - len(true_classes)))

# Step 4.3: Generate and plot the confusion matrix
cm = confusion_matrix(true_labels, pred_labels, labels=[0, 1])  # Add '0' for background
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['background', 'KOALA'])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()


# Step 5: Visualize test predictions (Successes and Mistakes)
from mrcnn.visualize import display_instances
from mrcnn import visualize

import random

# Select 5 random image IDs from the test dataset
for i in random.sample(list(dataset_test.image_ids), 5):
    image = dataset_test.load_image(i)  # Load the image
    results = inference_model.detect([image], verbose=0)  # Perform detection

    # Visualize the prediction
    visualize.display_instances(
        image,
        results[0]['rois'],
        results[0]['masks'],
        results[0]['class_ids'],
        dataset_test.class_names,
        results[0]['scores']
    )

from mrcnn.utils import compute_ap, extract_bboxes
import numpy as np
import cv2  # Assurez-vous que OpenCV est installé
from mrcnn import utils

# Liste pour stocker les AP (Average Precision) pour chaque image
APs = []

# Parcourir toutes les images du dataset de test
for image_id in dataset_test.image_ids:
    # Charger l'image
    image = dataset_test.load_image(image_id)

    # Charger les données au sol (ground truth): masques et IDs de classe
    gt_mask, gt_class_ids = dataset_test.load_mask(image_id)

    # Générer les boîtes englobantes au sol (à partir des masques si elles ne sont pas prédéfinies)
    gt_bbox = extract_bboxes(gt_mask)

    # Effectuer l'inférence sur l'image
    results = inference_model.detect([image], verbose=0)
    r = results[0]

    # Vérifier si des prédictions existent
    if r['masks'].size == 0:
        continue

    # Redimensionner les masques prédits pour correspondre aux masques au sol (si nécessaire)
    if r['masks'].shape[:2] != gt_mask.shape[:2]:
        pred_masks_resized = np.zeros(gt_mask.shape, dtype=np.uint8)
        for i in range(r['masks'].shape[-1]):
            pred_masks_resized[:, :, i] = cv2.resize(
                r['masks'][:, :, i].astype(np.uint8),
                (gt_mask.shape[1], gt_mask.shape[0]),
                interpolation=cv2.INTER_NEAREST
            )
        pred_masks = pred_masks_resized
    else:
        pred_masks = r['masks']

    # Passer les images sans données valides
    if gt_class_ids.size == 0 or r['class_ids'].size == 0:
        continue

    # Calculer l'AP pour l'image actuelle
    AP, precisions, recalls, overlaps = compute_ap(
        gt_bbox,          # Boîtes englobantes au sol
        gt_class_ids,     # IDs des classes au sol
        gt_mask,          # Masques au sol
        r['rois'],        # Boîtes englobantes prédites
        r['class_ids'],   # IDs des classes prédites
        r['scores'],      # Scores de confiance prédits
        pred_masks        # Masques prédits
    )

    APs.append(AP)

# Calcul et affichage de la moyenne de la précision moyenne (mAP)
if len(APs) > 0:
    mAP = np.mean(APs)
    print(f"Mean Average Precision (mAP): {mAP:.4f}")
else:
    print("Aucune prédiction valide trouvée pour l'évaluation.")

from mrcnn.utils import compute_ap, extract_bboxes
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score
import cv2
import json
from datetime import datetime

# Liste pour stocker les métriques pour chaque image
APs = []
all_true_labels = []
all_pred_labels = []

# Parcourir toutes les images du dataset de test
for image_id in dataset_test.image_ids:
    # Charger l'image
    image = dataset_test.load_image(image_id)

    # Charger les données au sol (ground truth): masques et IDs de classe
    gt_mask, gt_class_ids = dataset_test.load_mask(image_id)

    # Générer les boîtes englobantes au sol
    gt_bbox = extract_bboxes(gt_mask)

    # Effectuer l'inférence sur l'image
    results = inference_model.detect([image], verbose=0)
    r = results[0]

    # Passer les images sans prédictions
    if r['masks'].size == 0:
        continue

    # Redimensionner les masques prédits si nécessaire
    if r['masks'].shape[:2] != gt_mask.shape[:2]:
        pred_masks_resized = np.zeros(gt_mask.shape, dtype=np.uint8)
        for i in range(r['masks'].shape[-1]):
            pred_masks_resized[:, :, i] = cv2.resize(
                r['masks'][:, :, i].astype(np.uint8),
                (gt_mask.shape[1], gt_mask.shape[0]),
                interpolation=cv2.INTER_NEAREST
            )
        pred_masks = pred_masks_resized
    else:
        pred_masks = r['masks']

    # Passer les images sans données au sol ou sans prédictions valides
    if gt_class_ids.size == 0 or r['class_ids'].size == 0:
        continue

    # Calculer l'AP pour l'image actuelle
    AP, precisions, recalls, overlaps = compute_ap(
        gt_bbox,          # Boîtes englobantes au sol
        gt_class_ids,     # IDs des classes au sol
        gt_mask,          # Masques au sol
        r['rois'],        # Boîtes englobantes prédites
        r['class_ids'],   # IDs des classes prédites
        r['scores'],      # Scores de confiance prédits
        pred_masks        # Masques prédits
    )

    APs.append(AP)

    # Préparer les étiquettes pour sklearn
    # Convertir les masques en labels binaires par pixel
    gt_mask_binary = np.any(gt_mask > 0, axis=2).astype(np.int32)
    pred_mask_binary = np.any(pred_masks > 0, axis=2).astype(np.int32)

    # Aplatir les masques pour les métriques sklearn
    gt_mask_flat = gt_mask_binary.flatten()
    pred_mask_flat = pred_mask_binary.flatten()

    # Stocker les étiquettes aplaties
    all_true_labels.extend(gt_mask_flat)
    all_pred_labels.extend(pred_mask_flat)

# Convertir les listes en tableaux numpy pour sklearn
all_true_labels = np.array(all_true_labels)
all_pred_labels = np.array(all_pred_labels)

# Calcul des métriques globales
if len(APs) > 0:
    # Calculer mAP
    mAP = np.mean(APs)
    print(f"Mean Average Precision (mAP): {mAP:.4f}")

    # Calculer les métriques sklearn
    precision = precision_score(all_true_labels, all_pred_labels, average='binary')
    recall = recall_score(all_true_labels, all_pred_labels, average='binary')
    f1 = f1_score(all_true_labels, all_pred_labels, average='binary')

    # Afficher toutes les métriques
    print("\nOverall Metrics:")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")

    # Statistiques des AP par image
    print("\nPer-image AP Statistics:")
    print(f"Min AP: {np.min(APs):.4f}")
    print(f"Max AP: {np.max(APs):.4f}")
    print(f"Median AP: {np.median(APs):.4f}")
    print(f"Standard Deviation AP: {np.std(APs):.4f}")

    # Distribution détaillée des APs
    percentiles = [25, 50, 75, 90, 95]
    print("\nAP Percentiles:")
    for p in percentiles:
        print(f"{p}th percentile: {np.percentile(APs, p):.4f}")
else:
    print("No valid predictions found for evaluation")

# Sauvegarder les métriques dans un fichier JSON
metrics = {
    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "mAP": float(mAP) if len(APs) > 0 else None,
    "precision": float(precision) if len(APs) > 0 else None,
    "recall": float(recall) if len(APs) > 0 else None,
    "f1_score": float(f1) if len(APs) > 0 else None,
    "num_images_evaluated": len(APs),
    "ap_statistics": {
        "min": float(np.min(APs)) if len(APs) > 0 else None,
        "max": float(np.max(APs)) if len(APs) > 0 else None,
        "median": float(np.median(APs)) if len(APs) > 0 else None,
        "std": float(np.std(APs)) if len(APs) > 0 else None,
        "percentiles": {
            str(p): float(np.percentile(APs, p)) for p in percentiles if len(APs) > 0
        }
    }
}

with open('evaluation_metrics.json', 'w') as f:
    json.dump(metrics, f, indent=4)
print("\nMetrics saved to 'evaluation_metrics.json'")